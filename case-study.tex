% !TEX root = article.tex

\section{Case Study}
\label{se:case-study}

In this section we show how \osrkit\ can be used in a production VM to support aggressive optimizations for dynamic languages. We focus on MATLAB's \feval\ construct, a widely used built-in higher-order function that applies the function passed as first parameter to the remaining arguments (e.g., {\tt feval(g,x,y)} computes {\tt g(x,y)}). This feature is used in many classes of numerical computations that benefit from having functions as parameters.

\ifdefined\fullver such as iterative methods for approximate solutions of an ordinary differential equation (ODE) and simulated annealing heuristics to locate a good approximation to the global optimum of a function in a large search space.}\fi

\ifdefined\fullver
MATLAB is a popular dynamic language for scientific and numerical programming. Introduced in the late 1970s mainly as a scripting language for performing computations through efficient libraries, it has evolved over the years into a more complex programming language with support for high-level features such as functions, packages and object orientation. A popular feature of the language is the \feval\ construct, a built-in higher-order function that enables the invocation of the function specified as first argument with the remaining arguments for the \feval\ call, returning eventually the computed result. This feature is heavily used in many classes of numerical computations. 
\fi

A previous study by Lameed and Hendren~\cite{lameed2013feval} shows that the overhead of an \feval\ call is significantly higher than a direct call, especially in JIT-based execution environments such as McVM~\cite{chevalier2010mcvm} and the proprietary MATLAB JIT accelerator by Mathworks. In fact, the presence of an \feval\ instruction can disrupt the results of intra- and inter-procedural level for type and array shape inference analyses, which are key factors for efficient code generation. Furthermore, since \feval\ invocations typically require a fallback to an intepreter, parameters passed to an \feval\ are generally boxed to make them more generic.

\subsection{Extending McVM}
The McVM virtual machine is a complex research project developed at McGill and made of several software components, including: a front-end for lowering MATLAB programs to an intermediate representation called IIR that captures the high-level features of the language; an interpreter for running MATLAB functions and scripts in IIR format; a manager component to perform analyses on IIR; a JIT compiler based on LLVM for generating native code for a function, lowering McVM IIR to LLVM IR; a set of helper components to perform fast vector and matrix operations using optimized libraries such as ATLAS, BLAS and LAPACK. %The architecture of McVM is illustrated in Figure [...]

McVM implements a function versioning mechanism based on type specialization: for each IIR representation of a function, different IR versions are generated according to the types of the arguments at each call site. The number of generated versions per function is on average small (i.e., less than two), as in most cases functions are always called with the same argument types. Type specialization is the main driver for generating efficient code in McVM~\cite{chevalier2010mcvm}.

The source code of McVM is publicly available~\cite{mcvm}; after porting it from the LLVM legacy JIT to MCJIT, we have extended it with the following components to enable the optimization of \feval\ instructions:
\begin{enumerate}
\item An analysis pass to identify optimization opportunities for \feval\ instructions in the IIR of a function
\item An extension for the IIR compiler to track the correspondence between IIR and IR objects at \feval\ sites
\item An inserter component to insert OSR points in the IR for IIR locations annotated during the analysis pass
\item An optimizer module triggered at OSR points, which in turn is made of:
\begin{enumerate}
\item A profile-driven IIR generator to replace \feval\ calls with direct calls
\item A helper component to lower the optimized IIR function to IR and construct a state mapping 
\item A code caching mechanism to handle the compilation of the continuation functions
\end{enumerate}
\end{enumerate}

We integrated our analysis pass in McVM's analysis manager. In particular, we group \feval\ instructions whose first argument is reached by the same definition, and for each group we mark for instrumentation only instructions not dominated by others, so that the function can be optimized as early as possible at run-time.

The analysis pass is also able to determine whether the value of the argument can change across two executions of the same \feval\ instruction, thus discriminating when a run-time guard must be inserted during the run-time optimization phase. Compared to the OSR-based approach by Lameed and Hendren, our solution is cheaper because the types for the other arguments do not need to be cached or guarded: as we will see later on, the type inference engine will compute the most accurate yet sound type information in the analysis of the optimized IIR where direct calls are used.

When the IIR compiler processes an annotated \feval\ instruction, it stores in the metadata of the function version being compiled the current variable map (i.e., a map between IIR and IR objects), the {\tt llvm::BasicBlock*} created for the \feval\ and the {\tt llvm::Value*} object corresponding to the first argument for the \feval. The last two objects are used by the inserter component as source label and {\tt val} argument for inserting an open OSR point. The open-OSR stub will in turn invoke the callback optimizer component we are about to present.

\subsection{Generating Optimized Code}
The core of our optimization pipeline is the optimizer module that is responsible for generating optimized code for the current function $f$ using the run-time value of the first argument for \feval and contextual information passed from the open-OSR stub. As a first step, the optimizer inspects {\tt val} to resolve the target of the call - which we call $g$ -  and check whether a previously compiled optimized function is available from the code cache. If not, a new function $f_{opt}$ is generated by cloning the IIR representation $f^{IIR}$ of $f$ into
 $f^{IIR}_{opt}$ and replacing all the \feval\ calls in the same group of the instrumented one with direct calls to $g$.

As a next step, the optimizer asks the IIR compiler to analyze $f^{IIR}_{opt}$ and generate optimized LLVM IR $f^{IR}_{opt}$, also making a copy of the variable map between IIR and IR objects when compiling the direct call corresponding to the \feval\ instruction that triggered the OSR.

This map is essential for the construction of a state mapping between $f^{IR}$ to $f^{IR}_{opt}$, as it is compared against the corresponding map stored during the lowering of $f$ to determine for each value in $f^{IR}_{opt}$ live at the continuation block whether:
\begin{itemize}
\item an {\tt llvm::Value*} from $f^{IR}$ passed as argument at the OSR point can be used directly
\item or, compensation code is required to reconstruct its value before jumping to the block.
\end{itemize}

\noindent In fact, since the type inference engine yields more accurate results for $f^{IIR}_{opt}$ compared to $f^{IIR}$, the IIR compiler can in turn generate efficient specialized IR code for representing and manipulating IIR variables, and compensation code is typically required to unbox or downcast some of the live values passed at the OSR point. Compensation code might also be required to materialize an IR object for an IIR variable that were previously accessed through get/set methods from the environment.

Once a state mapping object has been constructed, the optimizer calls our OSR library to generate the continuation function for the OSR transition and eventually compiles it. A pointer to the compiled function is stored in the code cache and returned to the stub, which invokes it through an indirect call passing the live state saved at the OSR point.
